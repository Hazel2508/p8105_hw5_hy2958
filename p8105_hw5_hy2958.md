p8105_hw5_hy2958
================
2025-11-14

``` r
library(tidyverse)
```

    ## â”€â”€ Attaching core tidyverse packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 2.0.0 â”€â”€
    ## âœ” dplyr     1.1.4     âœ” readr     2.1.5
    ## âœ” forcats   1.0.0     âœ” stringr   1.5.1
    ## âœ” ggplot2   3.5.2     âœ” tibble    3.3.0
    ## âœ” lubridate 1.9.4     âœ” tidyr     1.3.1
    ## âœ” purrr     1.1.0     
    ## â”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€
    ## âœ– dplyr::filter() masks stats::filter()
    ## âœ– dplyr::lag()    masks stats::lag()
    ## â„¹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
set.seed(1)
```

``` r
#problem 1
has_duplicate_birthday <- function(n) {
  birthdays <- sample(1:365, size = n, replace = TRUE)
  any(duplicated(birthdays))
}

birthday_prob_loop <- function(n, n_sim = 10000) {
  result <- logical(n_sim)  ##create all 'false' list
  for (i in 1:n_sim) {
    result[i] <- has_duplicate_birthday(n)
  }
  mean(result)
}


birthday_df <- tibble(
  group_size = 2:50,
  prob_shared = map_dbl(2:50, birthday_prob_loop)
)

#plot
birthday_df %>%
  ggplot(aes(x = group_size, y = prob_shared)) +
  geom_line()+
  labs(
    title = "Birthday Duplication Simulation",
    x = "Group Size",
    y = "Probability of Shared Birthday"
  ) 
```

![](p8105_hw5_hy2958_files/figure-gfm/unnamed-chunk-2-1.png)<!-- --> The
plot shows the estimated probability that at least two people in a group
share the same birthday changes with the group size.

When the group size is small, the probability is close to 0, as the
group size continues to increase, the probability grows quickly and
approaches 1.

``` r
#problem 2
simulate_one <- function(mu, n = 30, sigma = 5, alpha = 0.05) {
  x <- rnorm(n, mean = mu, sd = sigma)
  tibble(
    mu_hat = mean(x),
    p_value = t.test(x, mu = 0) |> broom::tidy() |> pull(p.value)
  )
}

simulate_many <- function(mu, nn=5000, n = 30, sigma = 5) {
  out <- vector("list", 5000) #create space
  for (i in 1:5000) {
    out[[i]] <- simulate_one(mu = mu, n = n, sigma = sigma)
  }
  bind_rows(out) |>
    mutate(mu_true = mu,
           reject = p_value < 0.05)
}

mu_grid <- 0:6
sim_all <- map_dfr(mu_grid, simulate_many, nn = 5000, n = 30, sigma = 5)

power_df <- sim_all %>% 
  group_by(mu_true)  %>% 
  summarise(power = mean(reject), .groups = "drop")

avg_overall <- sim_all  %>% 
  group_by(mu_true)  %>% 
  summarise(avg_mu_hat = mean(mu_hat), .groups = "drop")

avg_rejected <- sim_all  %>% 
  filter(reject)  %>% 
  group_by(mu_true)  %>% 
  summarise(avg_mu_hat_reject = mean(mu_hat), .groups = "drop")

#plots
#effect size and power
p_power <- ggplot(power_df, aes(x = mu_true, y = power)) +
  geom_line() + geom_point() +
  labs(title = "Power vs Effect Size (one-sample t-test)",
       x = expression(true~mu))

p_power
```

![](p8105_hw5_hy2958_files/figure-gfm/unnamed-chunk-3-1.png)<!-- -->

``` r
#the average estimate of ğœ‡Ì‚ and the true value of ğœ‡
p_avg_all <- ggplot(avg_overall, aes(x = mu_true, y = avg_mu_hat)) + 
  geom_line() + 
  geom_point() +
  labs(title = "Average of Sample Mean vs True Mean (All Samples)",
       x = expression(true~mu), y = expression(Mean~of~hat(mu)))

p_avg_all
```

![](p8105_hw5_hy2958_files/figure-gfm/unnamed-chunk-3-2.png)<!-- -->

``` r
#the average estimate of ğœ‡Ì‚ only in samples for which the null was rejected 

p_avg_reject <- ggplot(avg_rejected, aes(x = mu_true, y = avg_mu_hat_reject)) +
  geom_line() +
  geom_point() +
  labs(
    title = "Average of Sample Mean vs True Mean (Rejected Samples)",
    x = expression(True~mu),
    y = expression(Mean~of~hat(mu))
  ) 

p_avg_reject
```

![](p8105_hw5_hy2958_files/figure-gfm/unnamed-chunk-3-3.png)<!-- -->
plot1: The plot shows a positive association between effect size (true
Î¼) and power. As the true mean Î¼ moves farther from 0 (the null value),
the probability of rejecting Hâ‚€ increases sharply. When Î¼ â‰ˆ 0, power is
low (near the nominal Î± = 0.05 level). As Î¼ increases to around 2â€“3,
power rises quickly above 0.5, and for Î¼ â‰¥ 4, power approaches 1.

plot2&3: The sample average of mu hat where the null is rejected is not
approximately equal to the true value of mu

This happens because of selection bias, when we condition on statistical
significance (p \< 0.05), we only keep the samples with unusually large
sample means (those that happened to deviate most from 0).

``` r
#problem 3.1
data = read_csv("./homicide-data.csv") %>% 
  mutate(city_state = str_c(city, ", ", state)) 
```

    ## Rows: 52179 Columns: 12
    ## â”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ## Delimiter: ","
    ## chr (9): uid, victim_last, victim_first, victim_race, victim_age, victim_sex...
    ## dbl (3): reported_date, lat, lon
    ## 
    ## â„¹ Use `spec()` to retrieve the full column specification for this data.
    ## â„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
city_homicide <- data %>% 
group_by(city_state) %>%
  summarize(
    total = n(),
    unsolved = sum(disposition %in% c("Closed without arrest", "Open/No arrest"))
    ) 

city_homicide
```

    ## # A tibble: 51 Ã— 3
    ##    city_state      total unsolved
    ##    <chr>           <int>    <int>
    ##  1 Albuquerque, NM   378      146
    ##  2 Atlanta, GA       973      373
    ##  3 Baltimore, MD    2827     1825
    ##  4 Baton Rouge, LA   424      196
    ##  5 Birmingham, AL    800      347
    ##  6 Boston, MA        614      310
    ##  7 Buffalo, NY       521      319
    ##  8 Charlotte, NC     687      206
    ##  9 Chicago, IL      5535     4073
    ## 10 Cincinnati, OH    694      309
    ## # â„¹ 41 more rows

``` r
baltimore <- city_homicide %>%
  filter(city_state == "Baltimore, MD") 

baltimore_test <- prop.test(
  x = baltimore$unsolved,     
  n = baltimore$total         
)

baltimore_tidy <- broom::tidy(baltimore_test)%>%
  select(estimate, conf.low, conf.high)

baltimore_tidy
```

    ## # A tibble: 1 Ã— 3
    ##   estimate conf.low conf.high
    ##      <dbl>    <dbl>     <dbl>
    ## 1    0.646    0.628     0.663

The raw data contains 52179 observations and 12 variables, included the
location of the killing, whether an arrest was made and, in most cases,
basic demographic information about each victim.

``` r
#problem 3.2
city_props <- city_homicide  %>%
  mutate(
    test = purrr::map2(unsolved, total, ~ prop.test(x = .x, n = .y)),
    tidy = purrr::map(test, broom::tidy) 
    ) %>%
  unnest(tidy) %>%      # unfold list-column
  select(city_state, total, unsolved, estimate, conf.low, conf.high) %>%
  arrange(desc(estimate)) #reorder
```

    ## Warning: There was 1 warning in `mutate()`.
    ## â„¹ In argument: `test = purrr::map2(unsolved, total, ~prop.test(x = .x, n =
    ##   .y))`.
    ## Caused by warning in `prop.test()`:
    ## ! Chi-squared approximation may be incorrect

``` r
city_props %>%
  mutate(city_state = fct_reorder(city_state, estimate)) %>%
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0) +
   labs(
    title = "Proportion of Unsolved Homicides by City (95% CI)",
    x = "City State",
    y = "Estimated proportion unsolved"
  ) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))
```

![](p8105_hw5_hy2958_files/figure-gfm/unnamed-chunk-5-1.png)<!-- -->
